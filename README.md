## Hiring: [aka.ms/nlpagi](https://aka.ms/nlpagi)
We are hiring at all levels (including FTE researchers and interns)! If you are interested in working with us on Foundation Models (aka large-scale pre-trained models) and AGI, NLP, MT, Speech, Document AI and Multimodal AI, please send your resume to <a href="mailto:fuwei@microsoft.com" class="x-hidden-focus">fuwei@microsoft.com</a>.

# LMOps: Language Model Operationalization



## News
- Dec, 2022: [Optimizing Prompts for Text-to-Image Generation](#) (incoming)
- Dec, 2022: [Structured Prompting: Scaling In-Context Learning to 1,000 Examples](#)
- Nov, 2022: [Extensible Prompts for Language Models](https://arxiv.org/abs/2212.00616)

## Links

- [microsoft/unilm](https://github.com/microsoft/unilm): Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities
- [microsoft/torchscale](https://github.com/microsoft/torchscale): Transformers at (any) Scale

## License
This project is licensed under the license found in the LICENSE file in the root directory of this source tree.
Portions of the source code are based on the [transformers](https://github.com/huggingface/transformers) project.

[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct)

### Contact Information

For help or issues using the pre-trained models, please submit a GitHub issue.

For other communications, please contact [Furu Wei](http://gitnlp.org/) (`fuwei@microsoft.com`).
